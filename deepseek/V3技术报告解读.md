# V3 技术报告解读

R1脱胎于V3，V3作为一个MoE模型有大量的创新技术，我们逐步的进行解读

## V3的总体介绍

### 总结
![V3技术总结](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/Deepseek%20v3%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A%E6%A0%B8%E5%BF%83%E8%A7%A3%E8%AF%BB%E4%B8%80.png)

### 高效的训练技术
![高效的训练技术](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83%E6%80%BB%E4%BD%93%E6%8A%80%E6%9C%AF%E8%B4%A1%E7%8C%AE.png)

### 训练流程
![训练流程](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.png)

### 推理性能支撑
![推理性能支撑](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E9%AB%98%E6%95%88%E6%8E%A8%E7%90%86%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF%E6%94%AF%E6%92%91%E6%A0%B8%E5%BF%83%E8%A6%81%E7%B4%A0.png)


## V3训练效率和performance提升的关键

**我们知道MoE架构的router的负载是一个非常核心的技术，负载不均衡会导致训练的失败，那么通常的方法是引入辅助函数，但是辅助函数往往又会影响效率，这是一个进退两难的问题。Deepseek成功的使用了无辅助训练的方式，即保持了负载的平衡又解决了性能的问题。**

### 有辅助GShard技术
**GShard是谷歌发布的一个MoE训练技术，通过双层辅助控制有效解决了负载问题。介绍V3的无辅助之前，我们先看下有辅助的技术**

**GShard总体介绍**

![GShard总体介绍](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/gshard%E6%80%BB%E4%BD%93%E4%BB%8B%E7%BB%8D.png)



**GShard技术细节**


![GShard技术细节](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/Gshard%E7%BB%86%E8%8A%82.png)



**Gshard优势**


![Gshard优势](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/Gshard%E7%9B%B8%E5%AF%B9%E4%BA%8Etopk%E7%9A%84%E5%AF%B9%E6%AF%94.png)



### MLA(Multi-Latent-Attention)机制

**MLA技术能极大的提升训练效率和推理性能。其核心在于贡献K、V矩阵，减少了参数规模。**


**MLA的价值**
![MLA](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/MLA%E7%9A%84%E5%88%9B%E6%96%B0%E4%B8%8E%E5%B7%A5%E7%A8%8B%E4%BB%B7%E5%80%BC.png)


**MLA的核心在于矩阵降秩压缩**
![降秩](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/MLA%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90.png)


### V3的无辅助训练技术


**相较于Gshard， V3在使用超参做负载均衡控制，token序列中引入辅助控制，非常”轻“的辅助做了负载均衡控制，很牛掰。看公式可能觉得不复杂，但是能在600B+14T的规模下稳定做出来，真的牛。尤其是里面关乎node和expert的控制策略，对计算通信overlap的充分挖觉，不得不说算法和算法工程的配合相当牛逼！**


**总体设计方案**

![总体设计方案](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/deepseek_MoE_base_designe.png)


**路由调整策略**:——引入bias偏置，每个step进行调整，不参与训练过程汇总的后向梯度调整


![无辅助的负载方案](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/Deepseek%E6%97%A0%E8%BE%85%E5%8A%A9%E5%B9%B3%E8%A1%A1%E7%AD%96%E7%95%A5.png)



**序列辅助平衡**——引入序列内的辅助平衡


![技术细节](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E5%BA%8F%E5%88%97%E5%B9%B3%E8%A1%A1%E8%BE%85%E5%8A%A9%E7%AD%96%E7%95%A5.png)



**优异的分配策略使得训练过程中无token丢弃**

![无token丢弃](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/Deepseek%E6%97%A0token%E4%B8%A2%E5%BC%83.png)



### MTP(Multi-token-prediction)技术

**多token预测对于模型performance有很大帮助，另外mtp模块对于后续的推理优化（比如投机采样）也有很大的帮助，下面简要介绍MTP**

**先说价值**


![MTP的价值](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/mtp%E8%AE%BE%E8%AE%A1%E5%BD%B1%E5%93%8D.png)



**模型结构**
![模型结构](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/mtp%E5%A4%9Atoken%E9%A2%84%E6%B5%8B.png)


**计算过程**
![计算过程](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/MTP%E9%A2%84%E6%B5%8B%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png)


**优化目标函数**
![优化目标](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/MTP%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87.png)


**MTP训练时生效，推理时不使用（投机采样优化场景除外），那么MTP如何影响主模型，提升其performance呢？**
![MTP影响主模型的方式](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/mtp%E5%AF%B9%E4%B8%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E5%93%8D%E6%96%B9%E5%BC%8F.png)


### Infrastructure(持续更新)

**训练速度得益于多方面的努力，包括性能优异的集群，出色的并行调度技术和底层通信技术的优化。这一节介绍**


**训练框架**
![训练框架](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E6%A1%86%E6%9E%B6%E4%BC%98%E5%8C%96.png)


**集群规模**
![集群](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/%E9%9B%86%E7%BE%A4cluster.png)


#### DualPipe技术概览

**先看一下常见的PP并行优化。关于dp和tp此处就不再讲了。讲述3者的资料非常多。此处主要介绍PP并行的常见优化技术。核心在于减少空泡。如何减少空泡**
![pp并行](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/pp%E6%8A%80%E6%9C%AF.png)



**技术报告只是给出一个基本笼统的说法，具体细节估计要开源代码大家去看或者他们单独发一篇paper**
![dualpipe](https://github.com/xiangyuliu/material_arrangement/blob/local_edit_20250206/sources/image/dualpipe.png)



